{{- $db := mergeOverwrite .Values.db .Values.db.operator_install -}}
{{- $clusterName := include "clusterName" (dict
      "db" $db
      "Release" .Release
    ) -}}
apiVersion: "acid.zalan.do/v1"
kind: postgresql
metadata:
  name: {{ $clusterName }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "labels" $ | nindent 4 }}
    {{- if $db.exporter.enabled }}
    exporter: "true"
    {{- end }}
  {{- if $db.controller }}
  annotations:
    acid.zalan.do/controller: {{ $db.controller }}
  {{- end }}
spec:
  teamId: {{ $db.teamId }}
  volume: {{ toYaml $db.dbVolume | nindent 4 }}
  numberOfInstances: {{ .Values.replicas.db }}
  users:
    etrip: []
  databases:
    etrip: etrip
  postgresql:
    version: "11" # postgres >12 does not support OIDs
    parameters: {{ toYaml $db.dbParameters | nindent 6}}
  {{- with $db.resources }}
  resources: {{ toYaml . | nindent 4 }}
  {{- end }}
  {{- with $db.clone }}
  {{- if not .namespace }}
  clone: {{ toYaml . | nindent 4 }}
  {{- else }}
  clone:
    cluster: {{ $.Release.Name }}-source
  {{- end }}
  {{- end }}
  {{- with $db.standby }}
  {{- if .enabled }}
  standby:
    s3_wal_path: s3://{{ .bucket }}/spilo/{{ .name | default $clusterName }}/{{ .uid }}/wal/11
  {{- end }}
  {{- end }}
  {{- if $db.exporter.enabled }}
  sidecars:
  - name: exporter
    image: {{ $db.exporter.image }}
    ports:
    - name: http-prom
      containerPort: 9187
      protocol: TCP
    env:
    - name: DATA_SOURCE_NAME
      value: postgresql://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@localhost/postgres
  {{- if len $db.exporter.extraQueries }}
    - name: PG_EXPORTER_EXTEND_QUERY_PATH
      value: /queries.yaml
  additionalVolumes:
  - name: queries
    mountPath: /queries.yaml
    subPath: queries.yaml
    volumeSource:
      name: queries
      configMap:
        name: {{ $clusterName }}-queries
    targetContainers:
    - exporter
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ $clusterName }}-queries
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "labels" $ | nindent 4 }}
data:
  queries.yaml: |
    {{- toYaml $db.exporter.extraQueries | nindent 4 }}
  {{- end }}
  {{- end }}
{{- if and $db.clone $db.refresh }}
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ .Release.Name }}-refresh-sa
  namespace: {{ .Release.Namespace }}
  labels: 
    {{- include "labels" $ | nindent 4 }}
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: {{ .Release.Name }}-refresh-role
  namespace: {{ .Release.Namespace }}
  labels: 
    {{- include "labels" $ | nindent 4 }}
rules:
- apiGroups: [ acid.zalan.do ]
  resources: [ postgresqls ]
  resourceNames: [ {{ $clusterName }} ]
  verbs: [ get, delete ]
- apiGroups: [ acid.zalan.do ]
  resources: [ postgresqls ]
  verbs: [ create ]
- apiGroups: [ apps ]
  resources: [ deployments ]
  resourceNames: [ {{ .Release.Name }}-web ]
  verbs: [ get, patch ]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: {{ .Release.Name }}-refresh-rolebinding
  namespace: {{ .Release.Namespace }}
  labels: 
    {{- include "labels" $ | nindent 4 }}
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: {{ .Release.Name }}-refresh-role
subjects:
- kind: ServiceAccount
  name: {{ .Release.Name }}-refresh-sa
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: {{ .Release.Name }}-refresh-db
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "labels" $ | nindent 4 }}
spec:
  schedule: {{ $db.refresh }}
  concurrencyPolicy: Forbid
  jobTemplate:
    metadata:
      labels:
        cronjob-name: refresh-db
        {{- include "selectorLabels" . | nindent 8 }}
    spec:
      template:
        metadata:
          labels:
            cronjob-name: refresh-db
            {{- include "selectorLabels" . | nindent 12 }}
        spec:
          restartPolicy: Never
          serviceAccountName: {{ .Release.Name }}-refresh-sa
          containers:
          - name: kubectl
            command: [ /bin/sh ]
            args:
            - -c
            - |
              kubectl get postgresql $ETRIP_CLUSTER -o yaml > /tmp/temp.yaml
              kubectl delete -f /tmp/temp.yaml
              sleep 5
              kubectl create -f /tmp/temp.yaml
              sleep 5
              while [ "$(kubectl get -f /tmp/temp.yaml -o jsonpath='{.status.PostgresClusterStatus}')" != 'Running' ]; do
                echo "Waiting for ready state"
                sleep 5
              done
              kubectl rollout restart deploy/${ETRIP_RELEASE}-web
            image: bitnami/kubectl
            env:
            - name: ETRIP_RELEASE
              value: {{ .Release.Name }}
            - name: ETRIP_CLUSTER
              value: {{ $clusterName }}
{{- end }}
{{- if $db.clone }}
{{- if $db.clone.namespace }}
---
apiVersion: v1
kind: Secret
metadata:
  name: standby.{{ .Release.Name }}-source.credentials
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "labels" . | nindent 4 }}
  annotations:
    reflector.v1.k8s.emberstack.com/reflects: "{{- $db.clone.namespace -}} /standby.
      {{- $db.clone.cluster | default $clusterName -}} .credentials"
type: Opaque
---
apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-source
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "labels" . | nindent 4 }}
spec:
  type: ExternalName
  externalName: {{ $db.clone.cluster | default $clusterName -}} .
    {{- $db.clone.namespace -}} .svc.cluster.local
  ports:
  - name: postgres
    port: 5432
    protocol: TCP
    targetPort: 5432
{{- end }}
{{- end }}
